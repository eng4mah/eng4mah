
# --------------------------------------------------------------
# RegTech Assistance â€“ Streamlit UI (Ù…ÙØ­Ø¯Ù‘ÙØ«)
# --------------------------------------------------------------

import os
import re
from pathlib import Path
from typing import List, Dict, Generator, Optional, Tuple

import streamlit as st

# --------------------------- Cerebras SDK ---------------------------
try:
    from cerebras.cloud.sdk import Cerebras
except ImportError:                                   # pragma: no cover
    st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Cerebras SDK: `pip install cerebras-cloud-sdk`")
    st.stop()

# --------------------------- Optional tokeniser --------------------
# tiktoken Ù‡Ùˆ Ù†ÙØ³ Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø°ÙŠ ØªØ³ØªØ¹Ù…Ù„Ù‡ Ù†Ù…Ø§Ø°Ø¬ OpenAI/Cerebras.
# Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙˆÙØ±ØŒ Ù†Ø¹ÙˆØ¯ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨ ØªÙ‚Ø±ÙŠØ¨ÙŠ (Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª).
try:
    import tiktoken
except Exception:
    tiktoken = None

def count_tokens(text: str) -> int:
    """Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙˆØ² Ø¨Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© Cerebras (Ù…Ø¹ fallback Ø¨Ø³ÙŠØ·)."""
    if not text:
        return 0
    if tiktoken:
        try:
            # Ù†Ù…ÙˆØ°Ø¬ gptâ€‘ossâ€‘120b ÙŠØ³ØªØ®Ø¯Ù… Ù†ÙØ³ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¹Ø§Ù… (cl100k_base)
            enc = tiktoken.get_encoding("cl100k_base")
            return len(enc.encode(text))
        except Exception:
            pass
    # ØªÙ‚Ø±ÙŠØ¨ Ø¨Ø³ÙŠØ· â€“ ÙƒÙ„ ÙƒÙ„Ù…Ø© â‰ˆ 1.33 Ø±Ù…Ø² (Ù…Ù‚Ø§Ø±Ø¨Ø© Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©)
    return int(len(text.split()) * 1.33)


# --------------------------- PDF / DOCX / Image utilities ----------
try:
    import pypdf
except Exception:
    pypdf = None

try:
    import pdfminer.high_level as pdfminer
except Exception:
    pdfminer = None

try:
    import fitz                     # PyMuPDF
except Exception:
    fitz = None

try:
    from pdf2image import convert_from_path
    from PIL import Image
    import pytesseract
except Exception:
    convert_from_path = None
    Image = None
    pytesseract = None

try:
    import docx
except Exception:
    docx = None

# --------------------------- Paths & config -------------------------
def get_repo_root() -> str:
    return os.path.abspath(os.path.dirname(__file__))


REPO_ROOT = get_repo_root()
FOLDER_PATH = os.path.join(REPO_ROOT, "legal_docs")
SUMMARY_FOLDER_PATH = os.path.join(REPO_ROOT, "summary")
RULES_FILE_PATH = os.path.join(REPO_ROOT, "RULES.txt")

API_KEY = os.getenv("CEREBRAS_API_KEY") or st.secrets.get("CEREBRAS_API_KEY", "")
if not API_KEY:                                           # pragma: no cover
    st.error("â— Ù…ÙØªØ§Ø­ Cerebras ØºÙŠØ± Ù…ÙØ¹Ø±Ù‘ÙÙ.")
    st.stop()
client = Cerebras(api_key=API_KEY)

# --------------------------- Feature flags -------------------------
USE_SUMMARY_FOR_SELECTION = True
USE_TWO_STEP_SELECTION = True
MAX_DOCS_FOR_SELECTION = 1
SELECTION_RETRY_ATTEMPTS = 3

# --------------------------- Helpers -------------------------------
def safe_run(fn):
    """Decorator Ù„Ø§Ù„ØªÙ‚Ø§Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª ÙˆØ¹Ø±Ø¶Ù‡Ø§ ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© Streamlit."""
    def wrapper(*args, **kwargs):
        try:
            return fn(*args, **kwargs)
        except Exception as exc:                         # pragma: no cover
            st.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {exc}")
            st.exception(exc)
    return wrapper


# ---------- PDF cascade ----------
def _extract_pdf_with_pypdf(path: str) -> str:
    if not pypdf:
        return ""
    try:
        with open(path, "rb") as f:
            reader = pypdf.PdfReader(f)
            return "".join(page.extract_text() or "" for page in reader.pages)
    except Exception:
        return ""


def _extract_pdf_with_pdfminer(path: str) -> str:
    if not pdfminer:
        return ""
    try:
        return pdfminer.extract_text(path) or ""
    except Exception:
        return ""


def _extract_pdf_with_fitx(path: str) -> str:
    if not fitz:
        return ""
    try:
        doc = fitz.open(path)
        return "".join(page.get_text() for page in doc)
    except Exception:
        return ""


def _ocr_pdf(path: str) -> str:
    if not (convert_from_path and pytesseract and Image):
        return ""
    try:
        images = convert_from_path(path, dpi=300, fmt="png")
        txt = ""
        for img in images:
            if not isinstance(img, Image.Image):
                img = Image.open(img)
            txt += pytesseract.image_to_string(img) + "\n"
        return txt
    except Exception:
        return ""


def _read_docx(path: str) -> str:
    if not docx:
        return ""
    try:
        d = docx.Document(path)
        return "\n".join(p.text for p in d.paragraphs)
    except Exception:
        return ""


def _read_image(path: str) -> str:
    if not (pytesseract and Image):
        return ""
    try:
        return pytesseract.image_to_string(Image.open(path))
    except Exception:
        return ""


def read_file_content(file_path: str) -> Tuple[str, str]:
    """
    Ø¥Ø±Ø¬Ø§Ø¹ (Ø§Ø³Ù…â€‘Ø§Ù„Ù…Ù„Ù, Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬) Ù„Ø£ÙŠ ØµÙŠØºØ© Ù…Ø¯Ø¹ÙˆÙ…Ø©.
    PDFs â†’ cascadeØŒ DOCX â†’ pythonâ€‘docxØŒ ØµÙˆØ± â†’ OCRØŒ ØºÙŠØ± Ø°Ù„Ùƒ â†’ Ù†Øµ Ø¹Ø§Ø¯ÙŠ.
    """
    file_name = os.path.basename(file_path)
    text = ""

    if file_name.lower().endswith(".pdf"):
        text = _extract_pdf_with_pypdf(file_path)
        if not text.strip():
            text = _extract_pdf_with_pdfminer(file_path)
        if not text.strip():
            text = _extract_pdf_with_fitx(file_path)
        if not text.strip():
            text = _ocr_pdf(file_path)

    elif file_name.lower().endswith(".docx"):
        text = _read_docx(file_path)

    elif file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
        text = _read_image(file_path)

    else:   # Ù†Øµ Ø¹Ø§Ø¯ÙŠ
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read()
        except Exception:
            pass

    if not text.strip():
        st.warning(f"âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ù…Ù‚Ø±ÙˆØ¡ ÙÙŠ `{file_name}`.")
    return file_name, text


def get_document_names_from_folder() -> List[str]:
    if not os.path.isdir(FOLDER_PATH):
        st.warning(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {FOLDER_PATH}")
        return []
    return [
        f for f in os.listdir(FOLDER_PATH)
        if f.lower().endswith((".pdf", ".docx", ".txt", ".png", ".jpg", ".jpeg"))
    ]


def load_rules_file() -> str:
    if os.path.exists(RULES_FILE_PATH):
        _, txt = read_file_content(RULES_FILE_PATH)
        return txt
    return "Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®Ø§ØµØ©. Ø§ØªØ¨Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©."


def load_all_summaries() -> str:
    if not os.path.isdir(SUMMARY_FOLDER_PATH):
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø®ØµØ§Øª Ù…ØªØ§Ø­Ø©."
    out = ""
    for fname in sorted(os.listdir(SUMMARY_FOLDER_PATH)):
        if fname.lower().endswith(".txt"):
            _, txt = read_file_content(os.path.join(SUMMARY_FOLDER_PATH, fname))
            out += f"---\n{txt}\n---\n\n"
    return out or "Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ù„Ø®ØµØ§Øª."


def get_document_selection_with_summaries(
    question: str,
    doc_names: List[str],
    rules: str,
    summaries: str,
    max_docs: int,
) -> Optional[List[int]]:
    doc_list = "\n".join([f"#{i}: {n}" for i, n in enumerate(doc_names)])

    user_prompt = f"""
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ù†Ø³Ø¨ Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯Ø§Øª Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ {max_docs} Ù…Ù„Ù.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„Ù…Ù„Ø®ØµØ§Øª.

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{question}

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:
{rules}

Ù…Ù„Ø®ØµØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª:
{summaries}

Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
{doc_list}

Ø£Ø±Ø³Ù„ Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø¨ØµÙŠØºØ© #N Ø£Ùˆ #NONE Ø¥Ø°Ø§ Ù„Ø§ Ø´ÙŠØ¡ Ù…Ù†Ø§Ø³Ø¨.
""".strip()

    for attempt in range(SELECTION_RETRY_ATTEMPTS):
        try:
            resp = client.chat.completions.create(
                messages=[{"role": "user", "content": user_prompt}],
                model="gpt-oss-120b",
            )
            content = resp.choices[0].message.content or ""
            nums = re.findall(r"#(\d+)", content)

            if nums:
                indices = [int(x) for x in nums if 0 <= int(x) < len(doc_names)]
                if indices:
                    return indices[:max_docs]

            if "#NONE" in content.upper():
                return []
        except Exception as e:                     # pragma: no cover
            st.error(f"âŒ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙØ´Ù„Øª ({attempt+1}/{SELECTION_RETRY_ATTEMPTS}): {e}")
            continue
    return None


def get_cerebras_response_stream(prompt: str, chat_history: List[Dict[str, str]]) -> Generator[str, None, None]:
    messages = chat_history + [{"role": "user", "content": prompt}]
    try:
        stream = client.chat.completions.create(
            messages=messages,
            model="gpt-oss-120b",
            stream=True,
        )
        for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content
    except Exception as e:                         # pragma: no cover
        err = f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù€ API: {e}"
        st.error(err)
        yield err


def build_prompt(task: str, rules: str, context: str, question: Optional[str] = None) -> str:
    q_sec = f"\nØ³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n---\n{question}\n---\n" if question else ""
    return f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ "RegTech Assistance". Ø§ØªØ¨Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©:

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù„Ø²Ù…Ø©:
{rules}

Ø§Ù„Ù…Ù‡Ù…Ø©:
{task}

Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚:
{context if context else "Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£Ùˆ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ«Ø§Ø¦Ù‚."}
{q_sec}
"""


# ------------------------------------------------------------------
# 7ï¸âƒ£  ÙˆØ§Ø¬Ù‡Ø© Streamlit
# ------------------------------------------------------------------
@safe_run
def main():
    st.set_page_config(page_title="RegTech Assistance", page_icon="âš–ï¸", layout="centered")

    # ----------------- CSS Ø¹Ø§Ù… -----------------
    st.markdown(
        """
        <style>
        body { direction: rtl; text-align: right; }
        input, textarea { text-align: right !important; }
        .stChatMessage, .stChatMessage > div { opacity: 1 !important; }

        /* Ø²Ø± Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø«Ø§Ø¨Øª â€“ Ø£Ø³ÙÙ„â€‘ÙŠØ³Ø§Ø± */
        .clear-btn {
            position: fixed;
            bottom: 12px;
            left: 12px;
            z-index: 9999;
            background: none;
            border: none;
            font-size: 1.8rem;
            cursor: pointer;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # ----------------- Ø²Ø± Ø§Ù„Ù…Ø³Ø­ Ø§Ù„Ø«Ø§Ø¨Øª -----------------
    # ÙŠØ¬Ø±Ù‰ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø© => Ù…Ø³Ø­ ÙƒÙ„ Ø§Ù„Ù€ session state
    st.markdown(
        """
        <button class="clear-btn" title="Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"
                onclick="window.location.reload();">ğŸ§¹</button>
        """,
        unsafe_allow_html=True,
    )

    # ----------------- Session State -----------------
    for key, default in {
        "messages": [],
        "doc_names": [],
        "rules_content": "",
        "docs_loaded_first_time": False,
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    # ----------------- Ø£ÙˆÙ„ ØªØ­Ù…ÙŠÙ„ Ù„Ù„Ù…Ù„ÙØ§Øª/Ø§Ù„Ù…Ø¬Ù„Ø¯ -----------------
    if not st.session_state.docs_loaded_first_time:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…â€¦"):
            os.makedirs(FOLDER_PATH, exist_ok=True)
            os.makedirs(SUMMARY_FOLDER_PATH, exist_ok=True)

            if not os.path.exists(RULES_FILE_PATH):
                with open(RULES_FILE_PATH, "w", encoding="utf-8") as f:
                    f.write("Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®Ø§ØµØ©. Ø§ØªØ¨Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©.")

            st.session_state.doc_names = get_document_names_from_folder()
            st.session_state.rules_content = load_rules_file()
            st.session_state.docs_loaded_first_time = True
            st.toast(f"âœ… Ø¹ÙØ«Ø± Ø¹Ù„Ù‰ {len(st.session_state.doc_names)} ÙˆØ«ÙŠÙ‚Ø©.", icon="âœ…")

    # ----------------- Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„ -----------------
    if not st.session_state.messages:
        st.markdown(
            "<div style='color:#a0a0a0; text-align:right'>Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙˆØ«Ø§Ø¦Ù‚Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ âš–ï¸</div>",
            unsafe_allow_html=True,
        )
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            if msg.get("is_review_notice"):
                st.info(msg["content"])
            else:
                st.markdown(msg["content"])

    # ----------------- Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… -----------------
    if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† Ù…Ø³ØªÙ†Ø¯Ø§ØªÙƒ â€¦"):
        # Ø­ÙØ¸ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # ------------ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ------------
        with st.chat_message("assistant"):
            final_context = ""
            context_docs = []

            # ----- Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØ¹Ù„Ø§Ù‹ -----
            if USE_TWO_STEP_SELECTION and st.session_state.doc_names:
                with st.spinner("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚â€¦"):
                    all_summaries = load_all_summaries()
                    selected_idxs = get_document_selection_with_summaries(
                        prompt,
                        st.session_state.doc_names,
                        st.session_state.rules_content,
                        all_summaries,
                        MAX_DOCS_FOR_SELECTION,
                    )

                if selected_idxs is None:
                    err = "âŒ ÙØ´Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª. Ø±Ø¬Ø§Ø¡Ù‹ Ø£Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©."
                    st.error(err)
                    st.session_state.messages.append({"role": "assistant", "content": err})
                    st.rerun()
                elif not selected_idxs:
                    st.info("âš™ï¸ Ù„Ù… ØªÙØ­Ø¯ÙÙ‘Ø¯ ÙˆØ«Ø§Ø¦Ù‚ ØµØ§Ù„Ø­Ø© â€“ Ø³ÙŠÙØ³ØªÙ†Ø¯ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙ‚Ø·.")
                else:
                    chosen = [
                        st.session_state.doc_names[i]
                        for i in selected_idxs
                        if 0 <= i < len(st.session_state.doc_names)
                    ]
                    notice = "Ø³Ø£Ø±Ø§Ø¬ÙØ¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„ØªØ§Ù„ÙŠØ©:\n\n" + "\n".join(f"- `{n}`" for n in chosen)
                    st.info(notice)
                    st.session_state.messages.append(
                        {"role": "assistant", "content": notice, "is_review_notice": True}
                    )
                    with st.spinner("ØªØ­Ù…ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚â€¦"):
                        for n in chosen:
                            _, txt = read_file_content(os.path.join(FOLDER_PATH, n))
                            if txt:
                                context_docs.append({"source": n, "content": txt})
                    final_context = "\n\n---\n\n".join(
                        f"Ø§Ù„Ù…ØµØ¯Ø±: {d['source']}\n\nØ§Ù„Ù…Ø­ØªÙˆÙ‰: {d['content']}"
                        for d in context_docs
                    )
            else:
                st.info("âš™ï¸ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ù…Ø¹Ø·Ù„ â€“ Ø³ÙŠØªÙ… Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙ‚Ø·.")

            # ----- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ -----
            with st.spinner("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯â€¦"):
                task = "Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙÙ‚Ø·."
                full_prompt = build_prompt(task, st.session_state.rules_content, final_context, prompt)

                # ØªØ­Ø¶ÙŠØ± Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø¨Ø¯ÙˆÙ† Ø±Ø³Ø§Ø¦Ù„ â€œnoticeâ€)
                history_for_api = [
                    {"role": m["role"], "content": m["content"]}
                    for m in st.session_state.messages[:-1]   # Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø®ÙŠØ±
                    if not m.get("is_review_notice")
                ]

                placeholder = st.empty()
                answer = ""

                for chunk in get_cerebras_response_stream(full_prompt, history_for_api):
                    answer += chunk
                    placeholder.markdown(answer + "â–Œ")

                # Ø¹Ø¯Ø¯ Ø§Ù„Ø±Ù…ÙˆØ² (Ø­Ø³Ø¨ Ù…Ø­Ù„Ù„ Cerebras Ø£Ùˆ ØªÙ‚Ø±ÙŠØ¨ÙŠ)
                token_cnt = count_tokens(answer)
                answer_with_tokens = f"{answer} ({token_cnt}t)"
                placeholder.markdown(answer_with_tokens)

                # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
                if answer:
                    st.session_state.messages.append(
                        {"role": "assistant", "content": answer_with_tokens}
                    )

            # ----- ØªÙ…Ø±ÙŠØ± Ø§Ù„ØµÙØ­Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø£Ø³ÙÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ -----
            st.markdown(
                """
                <script>
                const el = window.parent.document.querySelector('.stApp');
                if (el) { el.scrollTo({top: el.scrollHeight, behavior: 'smooth'}); }
                </script>
                """,
                unsafe_allow_html=True,
            )

# ----------------------------------------------------------------------
if __name__ == "__main__":
    main()