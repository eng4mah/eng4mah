
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
RegTech Assistant â€“ Streamlit app
---------------------------------

The same code works on Streamlit Cloud (GitHubâ€‘mounted) **and** on a local
machine.  No modifications are required to switch between the two
environments.

Prerequisites
~~~~~~~~~~~~~
pip install -r requirements.txt          # streamlit, langchain, pypdf,
                                         # python-docx, pillow, pytesseract,
                                         # requests
# Optional OCR support:
#   Linux:   sudo apt-get install tesseract-ocr
#   macOS:   brew install tesseract

Set your DeepSeek API key as an environment variable
`DEEPSEEK_API_KEY` **or** in `.streamlit/secrets.toml`:

    DEEPSEEK_API_KEY = "sk-..."

Run:
    streamlit run app.py
"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Imports
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from __future__ import annotations

import os
import re
import json
import time
import datetime
import requests
from typing import List, Dict, Generator, Optional, Tuple

import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Optional heavy libraries (PDF, DOCX, OCR)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from langchain_core.documents import Document
    import pypdf
    import docx
    from PIL import Image
    import pytesseract
    LIBRARIES_AVAILABLE = True
except Exception as e:                     # catches ImportError and any runtime errors
    st.error(f"â— Ù…ÙƒØªØ¨Ø© Ù†Ø§Ù‚ØµØ© Ø£Ùˆ ØºÙŠØ± Ù…ÙØ«Ø¨ØªØ©: {e}")
    LIBRARIES_AVAILABLE = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Configuration â€“ paths are resolved dynamically
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_repo_root() -> str:
    """
    Detect the repository root.

    1ï¸âƒ£ Cloud layout: the repo is mounted under /mount/src/<repo_name>/.
        Walk upwards until a folder containing `13.RegTech` is found.

    2ï¸âƒ£ Fallback: assume the script is running locally and return the
        directory that contains this file.
    """
    cwd = os.path.abspath(os.path.dirname(__file__))
    candidate = cwd
    for _ in range(5):
        if os.path.isdir(os.path.join(candidate, "13.RegTech")):
            return candidate
        candidate = os.path.abspath(os.path.join(candidate, ".."))
    return cwd   # local development fallback

# Resolve the root once â€“ used everywhere else
REPO_ROOT = get_repo_root()

# Fixed subâ€‘folders (relative to the detected root)
FOLDER_PATH = os.path.join(REPO_ROOT, "13.RegTech", "legal_docs")
SUMMARY_FOLDER_PATH = os.path.join(REPO_ROOT, "13.RegTech", "summary")
RULES_FILE_NAME = "RULES.txt"
RULES_FILE_PATH = os.path.join(REPO_ROOT, "13.RegTech", RULES_FILE_NAME)

# API configuration
DEEPSEEK_API_URL = "https://api.deepseek.com/chat/completions"
API_KEY = os.getenv("DEEPSEEK_API_KEY") or st.secrets.get("DEEPSEEK_API_KEY", "")

# Feature flags ---------------------------------------------------------------
USE_AUTO_SUMMARIZATION = True
USE_SUMMARY_FOR_SELECTION = True
USE_TWO_STEP_SELECTION = True
SELECTION_MAX_RETRIES = 3
MAX_DOCS_FOR_SELECTION = 1   # strict limit as requested

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Helper utilities
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def safe_run(fn):
    """Wrap the whole Streamlit app so uncaught exceptions are shown, not fatal."""
    def wrapper(*args, **kwargs):
        try:
            return fn(*args, **kwargs)
        except Exception as exc:
            st.error(f"â— Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {exc}")
            st.exception(exc)
    return wrapper


def read_file_content(file_path: str) -> Tuple[str, str]:
    """Read text from PDF, DOCX, TXT, or image (OCR). Returns (file_name, text)."""
    text = ""
    file_name = os.path.basename(file_path)

    try:
        with open(file_path, "rb") as f:
            if file_name.lower().endswith(".pdf"):
                reader = pypdf.PdfReader(f)
                for page in reader.pages:
                    text += page.extract_text() or ""
            elif file_name.lower().endswith(".docx"):
                doc = docx.Document(f)
                for para in doc.paragraphs:
                    text += para.text + "\n"
            elif file_name.lower().endswith((".png", ".jpg", ".jpeg")):
                try:
                    text = pytesseract.image_to_string(Image.open(f))
                except pytesseract.TesseractNotFoundError:
                    st.error("â— Tesseract ØºÙŠØ± Ù…ÙØ«Ø¨Øª Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø².")
                except Exception as ocr_e:
                    st.error(f"â— ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø© {file_name}: {ocr_e}")
            else:   # txt or any other plainâ€‘text fallback
                with open(file_path, "r", encoding="utf-8") as txt_f:
                    text = txt_f.read()
    except Exception as e:
        st.error(f"â— Ø®Ø·Ø£ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù {file_name}: {e}")

    return file_name, text


def get_document_names_from_folder(folder_path: str) -> List[str]:
    """Return a list of supported document names inside *folder_path*."""
    if not os.path.isdir(folder_path):
        st.warning(f"âš ï¸ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {folder_path}")
        return []

    supported = [
        f for f in os.listdir(folder_path)
        if f != RULES_FILE_NAME and f.lower().endswith(
            (".pdf", ".docx", ".txt", ".png", ".jpg", ".jpeg")
        )
    ]
    return supported


def load_rules_file(rules_path: str) -> str:
    """Load the RULES.txt file (or return a default message)."""
    if os.path.exists(rules_path):
        _, content = read_file_content(rules_path)
        return content
    return "Ù„Ø§ ØªÙˆØ¬Ø¯ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø®Ø§ØµØ©. Ø§ØªØ¨Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©."


def get_deepseek_response_blocking(prompt: str, api_key: str) -> Optional[str]:
    """Call DeepSeek once (nonâ€‘streaming) and return the answer."""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": prompt}],
        "stream": False,
    }

    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers=headers,
            json=payload,
            timeout=90,
        )
        response.raise_for_status()
        data = response.json()
        return data["choices"][0]["message"]["content"]
    except requests.RequestException as e:
        st.error(f"â— ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù€ API: {e}")
    except Exception as e:
        st.error(f"â— Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø¹Ù†Ø¯ Ø·Ù„Ø¨ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {e}")
    return None


def generate_and_save_summary(
    file_name: str,
    doc_folder: str,
    summary_folder: str,
    api_key: str,
) -> None:
    """Create a oneâ€‘paragraph summary for *file_name* if it does not exist."""
    summary_file = f"{os.path.splitext(file_name)[0]}_summary.txt"
    summary_path = os.path.join(summary_folder, summary_file)

    if os.path.exists(summary_path):
        return  # already cached

    st.info(f"â“ Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù„Ù€ `{file_name}`. Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ø§Ù„Ø¢Ù†â€¦")
    original_path = os.path.join(doc_folder, file_name)
    _, content = read_file_content(original_path)

    if not content.strip():
        st.warning(f"âš ï¸ Ø§Ù„Ù…Ù„Ù `{file_name}` ÙØ§Ø±Øº Ø£Ùˆ ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©.")
        return

    prompt = f"""
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ø®Øµ Ù…ÙˆØ¬Ø² Ù„Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„ØªØ§Ù„ÙŠ. Ø§ÙƒØªØ¨ Ø§Ù„Ù…Ù„Ø®Øµ ÙƒÙÙ‚Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…ØªØµÙ„Ø©
Ø¨Ø¯ÙˆÙ† Ù†Ù‚Ø§Ø· Ø£Ùˆ Ù‚ÙˆØ§Ø¦Ù…. Ù„Ø§ ØªØ¶Ù Ù…Ù‚Ø¯Ù…Ø§Øª Ø£Ùˆ Ø®ØªØ§Ù…Ø§Øª.

Ø§Ù„Ù…Ø³ØªÙ†Ø¯:
{content}
Ø§Ù„Ù…Ù„Ø®Øµ:
""".strip()

    with st.spinner(f"ğŸš§ ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ `{file_name}`â€¦"):
        summary = get_deepseek_response_blocking(prompt, api_key)

    if summary:
        try:
            os.makedirs(summary_folder, exist_ok=True)
            full_text = f"Ù…Ù„Ø®Øµ Ù…Ù„Ù: {file_name}\n\n{summary}"
            with open(summary_path, "w", encoding="utf-8") as f:
                f.write(full_text)
            st.toast(f"âœ… ØªÙ… Ø­ÙØ¸ Ù…Ù„Ø®Øµ `{file_name}`.", icon="ğŸ“")
        except Exception as e:
            st.error(f"â— ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ø®Øµ: {e}")
    else:
        st.error(f"â— ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ù„Ù„Ù…Ù„Ù `{file_name}`.")


def load_all_summaries(summary_folder: str) -> str:
    """Concatenate all summary txt files into a single string."""
    if not os.path.isdir(summary_folder):
        return "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…Ù„Ø®ØµØ§Øª Ù…ØªØ§Ø­Ø©."

    out = ""
    for fname in sorted(os.listdir(summary_folder)):
        if fname.lower().endswith(".txt"):
            _, txt = read_file_content(os.path.join(summary_folder, fname))
            out += f"---\n{txt}\n---\n\n"
    return out or "Ù„Ù… ÙŠÙØ¹Ø«Ø± Ø¹Ù„Ù‰ Ù…Ù„Ø®ØµØ§Øª."


def get_document_selection_with_summaries(
    question: str,
    doc_names: List[str],
    rules: str,
    summaries: str,
    api_key: str,
    max_docs: int,
) -> Optional[List[int]]:
    """Ask the LLM to pick the most relevant documents (max *max_docs*)."""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }

    doc_list = "\n".join([f"#{i}: {name}" for i, name in enumerate(doc_names)])

    user_prompt = f"""
Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ ØªØ­Ø¯ÙŠØ¯ Ø£Ù†Ø³Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…ØŒ
Ø¨Ø­Ø¯ Ø£Ù‚ØµÙ‰ {max_docs} Ù…Ù„Ù. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„Ù…Ù„Ø®ØµØ§Øª.

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{question}

Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¥Ù„Ø²Ø§Ù…ÙŠØ©:
{rules}

Ù…Ù„Ø®ØµØ§Øª Ø§Ù„Ù…Ù„ÙØ§Øª:
{summaries}

Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:
{doc_list}

Ø§Ù„Ø±Ø¯ ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø¨ØµÙŠØºØ© #N Ø£Ùˆ #NONE Ø¥Ø°Ø§ Ù„Ø§ Ø´ÙŠØ¡ Ù…Ù†Ø§Ø³Ø¨.
""".strip()

    payload = {
        "model": "deepseek-chat",
        "messages": [{"role": "user", "content": user_prompt}],
        "stream": False,
    }

    for attempt in range(SELECTION_MAX_RETRIES):
        try:
            resp = requests.post(
                DEEPSEEK_API_URL,
                headers=headers,
                json=payload,
                timeout=45,
            )
            resp.raise_for_status()
            data = resp.json()
            content = data["choices"][0]["message"]["content"]

            found = re.findall(r"#(\d+)", content)

            if found:
                indices = [int(i) for i in found if 0 <= int(i) < len(doc_names)]
                return indices[:max_docs]
            if "#NONE" in content.upper():
                return []
            st.warning(f"âš ï¸ Ø§Ø³ØªØ¬Ø§Ø¨Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø© Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ({attempt+1}/{SELECTION_MAX_RETRIES})")
            time.sleep(1)
        except Exception as e:
            st.error(f"â— ÙØ´Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚: {e}")
            return None

    st.error("â— ÙØ´Ù„ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø§Øª.")
    return None


def get_deepseek_response_stream(
    prompt: str,
    api_key: str,
    chat_history: List[Dict[str, str]],
    context_doc_count: int,
) -> Generator[str, None, None]:
    """Yield tokens from DeepSeek's streaming endpoint."""
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}",
    }
    messages = chat_history + [{"role": "user", "content": prompt}]
    payload = {
        "model": "deepseek-chat",
        "messages": messages,
        "stream": True,
    }

    try:
        resp = requests.post(
            DEEPSEEK_API_URL,
            headers=headers,
            json=payload,
            stream=True,
            timeout=60,
        )
        resp.raise_for_status()

        for line in resp.iter_lines():
            if not line:
                continue
            decoded = line.decode("utf-8")
            if not decoded.startswith("data: "):
                continue
            payload = decoded[6:].strip()
            if payload == "[DONE]":
                continue
            try:
                json_data = json.loads(payload)
                delta = json_data.get("choices", [{}])[0].get("delta", {})
                content = delta.get("content", "")
                if content:
                    yield content
            except json.JSONDecodeError:
                continue
    except requests.HTTPError as e:
        err_msg = f"â— ÙØ´Ù„ Ø§ØªØµØ§Ù„ API (ÙƒÙˆØ¯ {e.response.status_code})."
        if e.response.status_code == 400:
            err_msg += "\nØ§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø®ØªØ§Ø± Ø±Ø¨Ù…Ø§ ÙƒØ¨ÙŠØ± Ø¬Ø¯Ù‹Ø§."
        st.error(err_msg)
        yield err_msg
    except requests.RequestException as e:
        err_msg = f"â— ÙØ´Ù„ Ø§ØªØµØ§Ù„ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª: {e}"
        st.error(err_msg)
        yield err_msg
    except Exception as e:
        err_msg = f"â— Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}"
        st.error(err_msg)
        yield err_msg


def build_prompt(
    task_description: str,
    rules: str,
    context: str,
    question: Optional[str] = None,
) -> str:
    """Compose the final LLM prompt."""
    q_section = f"\nØ³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:\n---\n{question}\n---\n" if question else ""
    return f"""Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ "RegTech Assistance". Ø§ØªØ¨Ø¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ø¯Ù‚Ø©:

Ù‚ÙˆØ§Ø¹Ø¯ Ù…Ù„Ø²Ù…Ø©:
{rules}

Ø§Ù„Ù…Ù‡Ù…Ø©:
{task_description}

Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚:
{context if context else "Ù„Ù… ÙŠØªÙ… Ø§Ø®ØªÙŠØ§Ø± Ø£Ùˆ Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ ÙˆØ«Ø§Ø¦Ù‚."}
{q_section}
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@safe_run
def main() -> None:
    # --------------------------------------------------------------------- #
    # Page config â€“ must be first Streamlit command
    # --------------------------------------------------------------------- #
    st.set_page_config(
        page_title="RegTech Assistance",
        page_icon="âš–ï¸",
        layout="centered",
    )

    # --------------------------------------------------------------------- #
    # Basic sanity checks
    # --------------------------------------------------------------------- #
    if not LIBRARIES_AVAILABLE:
        st.stop()

    if not API_KEY or not API_KEY.startswith("sk-"):
        st.error("â— Ù…ÙØªØ§Ø­ DeepSeek ØºÙŠØ± Ù…Ø¶Ø¨ÙˆØ· (Ù…ØªØºÙŠÙ‘Ø± Ø§Ù„Ø¨ÙŠØ¦Ø© `DEEPSEEK_API_KEY`).")
        st.stop()

    # --------------------------------------------------------------------- #
    # Session state init
    # --------------------------------------------------------------------- #
    for key, default in {
        "messages": [],
        "doc_names": [],
        "rules_content": "",
        "docs_loaded_first_time": False,
        "action": None,
    }.items():
        if key not in st.session_state:
            st.session_state[key] = default

    # --------------------------------------------------------------------- #
    # Title + separator
    # --------------------------------------------------------------------- #
    st.title("RegTech Assistance")
    st.markdown("<hr/>", unsafe_allow_html=True)

    # --------------------------------------------------------------------- #
    # Main chat container
    # --------------------------------------------------------------------- #
    chat_container = st.container()
    with chat_container:
        # ------------------------------------------------- #
        # 1ï¸âƒ£ Firstâ€‘time loading of docs / rules / summaries
        # ------------------------------------------------- #
        if not st.session_state.docs_loaded_first_time:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙˆØ§Ù„Ù‚ÙˆØ§Ø¹Ø¯..."):
                # Create folders if they are missing (ignore errors on readâ€‘only FS)
                for p in (FOLDER_PATH, SUMMARY_FOLDER_PATH):
                    try:
                        os.makedirs(p, exist_ok=True)
                    except Exception as e:
                        st.warning(f"âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯ {p}: {e}")

                st.session_state.doc_names = get_document_names_from_folder(FOLDER_PATH)
                st.session_state.rules_content = load_rules_file(RULES_FILE_PATH)
                st.session_state.docs_loaded_first_time = True
                st.toast(
                    f"âœ… Ø¹ÙØ«Ø± Ø¹Ù„Ù‰ {len(st.session_state.doc_names)} ÙˆØ«ÙŠÙ‚Ø©.", icon="âœ…"
                )

            # ----- Autoâ€‘summarize if the flag is on -----
            if USE_AUTO_SUMMARIZATION and st.session_state.doc_names:
                st.write("ğŸ§ ÙØ­Øµ Ø§Ù„Ù…Ù„Ø®ØµØ§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ø§Ù‚ØµØ© â€¦")
                prog = st.progress(0)
                for i, name in enumerate(st.session_state.doc_names):
                    generate_and_save_summary(
                        name, FOLDER_PATH, SUMMARY_FOLDER_PATH, API_KEY
                    )
                    prog.progress((i + 1) / len(st.session_state.doc_names))
                prog.empty()

        # ------------------------------------------------- #
        # 2ï¸âƒ£ Action UI â€“ Upload / Summarize
        # ------------------------------------------------- #
        if st.session_state.action == "upload_doc":
            uploaded_file = st.file_uploader(
                "Ø§Ø®ØªØ± Ù…Ù„ÙÙ‹Ø§ Ù„ØªØ­Ù…ÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©",
                type=["pdf", "docx", "txt", "png", "jpg", "jpeg"],
            )
            if uploaded_file:
                target_path = os.path.join(FOLDER_PATH, uploaded_file.name)
                try:
                    with open(target_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())
                    st.toast(f"âœ… ØªÙ… Ø±ÙØ¹ `{uploaded_file.name}`", icon="âœ…")
                    if USE_AUTO_SUMMARIZATION:
                        generate_and_save_summary(
                            uploaded_file.name,
                            FOLDER_PATH,
                            SUMMARY_FOLDER_PATH,
                            API_KEY,
                        )
                except Exception as e:
                    st.error(f"â— ÙØ´Ù„ Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù (Ø§Ù„Ù‚Ø±Øµ Ø±Ø¨Ù…Ø§ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø·): {e}")

                # Force a reload of the doc list
                st.session_state.docs_loaded_first_time = False
                st.session_state.action = None
                st.rerun()

        if st.session_state.action == "summarize_doc":
            if st.session_state.doc_names:
                selected = st.selectbox(
                    "Ø§Ø®ØªØ± Ù…Ù„ÙÙ‹Ø§ Ù„ØªÙ„Ø®ÙŠØµÙ‡:",
                    options=st.session_state.doc_names,
                    index=None,
                    placeholder="Ø§Ø®ØªØ± Ù…Ù„Ù â€¦",
                )
                if selected:
                    st.session_state.messages.append(
                        {"role": "user", "content": f"Ù„Ø®Øµ Ù„ÙŠ Ø§Ù„Ù…Ù„Ù: `{selected}`"}
                    )
                    st.session_state.action = "processing_summary"
                    st.session_state.summarize_file = selected
                    st.rerun()
            else:
                st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ ÙˆØ«Ø§Ø¦Ù‚ Ù„ØªÙ„Ø®ÙŠØµÙ‡Ø§.")
                st.session_state.action = None

        # ------------------------------------------------- #
        # 3ï¸âƒ£ Display chat history
        # ------------------------------------------------- #
        if not st.session_state.messages:
            st.markdown(
                "<div style='text-align:center;color:#a0a0a0'>Ù…Ø±Ø­Ø¨Ø§Ù‹! ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ ÙˆØ«Ø§Ø¦Ù‚Ùƒ Ø§Ù„ÙŠÙˆÙ…ØŸ âš–ï¸</div>",
                unsafe_allow_html=True,
            )
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                if msg.get("is_review_notice"):
                    st.info(msg["content"])
                else:
                    st.markdown(msg["content"])

        # ------------------------------------------------- #
        # 4ï¸âƒ£ Process assistant actions
        # ------------------------------------------------- #
        if st.session_state.action == "processing_summary":
            with st.chat_message("assistant"):
                file_name = st.session_state.summarize_file
                with st.spinner(f"Ø¬Ø§Ø±ÙŠ ØªÙ„Ø®ÙŠØµ `{file_name}`â€¦"):
                    _, text = read_file_content(os.path.join(FOLDER_PATH, file_name))
                    if text:
                        task = "Ù„Ø®Øµ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¨Ø¯Ù‚Ø© ÙˆØ§Ø°ÙƒØ± Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©."
                        context = f"Ø§Ù„Ù…ØµØ¯Ø±: {file_name}\n\nØ§Ù„Ù…Ø­ØªÙˆÙ‰: {text}"
                        prompt = build_prompt(
                            task, st.session_state.rules_content, context
                        )
                        placeholder = st.empty()
                        full_resp = ""
                        for chunk in get_deepseek_response_stream(
                            prompt, API_KEY, [], 1
                        ):
                            full_resp += chunk
                            placeholder.markdown(full_resp + "â–Œ")
                        placeholder.markdown(full_resp)
                        st.session_state.messages.append(
                            {"role": "assistant", "content": full_resp}
                        )
                    else:
                        err = f"â— Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ `{file_name}`."
                        st.error(err)
                        st.session_state.messages.append(
                            {"role": "assistant", "content": err}
                        )
            st.session_state.action = None
            st.session_state.summarize_file = None
            time.sleep(0.1)
            st.rerun()

        # ------------------------------------------------- #
        # 5ï¸âƒ£ New user query
        # ------------------------------------------------- #
        if prompt := st.chat_input(
            "Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† Ù…Ø³ØªÙ†Ø¯Ø§ØªÙƒ â€¦",
            disabled=(st.session_state.action is not None),
        ):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("assistant"):
                final_context = ""
                context_docs: List[Document] = []

                # ---- 2â€‘step selection (if enabled) ----
                if USE_TWO_STEP_SELECTION and st.session_state.doc_names:
                    with st.spinner("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚â€¦"):
                        all_summaries = load_all_summaries(SUMMARY_FOLDER_PATH)
                        selected_idxs = get_document_selection_with_summaries(
                            prompt,
                            st.session_state.doc_names,
                            st.session_state.rules_content,
                            all_summaries,
                            API_KEY,
                            MAX_DOCS_FOR_SELECTION,
                        )

                    if selected_idxs is None:
                        err = "â— Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚."
                        st.error(err)
                        st.session_state.messages.append(
                            {"role": "assistant", "content": err}
                        )
                        st.rerun()
                    elif not selected_idxs:
                        st.info("âš™ï¸ Ù„Ù… ØªÙØ­Ø¯Ù‘ÙØ¯ ÙˆØ«Ø§Ø¦Ù‚ Ø°Ø§Øª ØµÙ„Ø© â€“ Ø³ÙŠÙØ³ØªÙ†Ø¯ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙ‚Ø·.")
                    else:
                        selected_names = [
                            st.session_state.doc_names[i]
                            for i in selected_idxs
                            if 0 <= i < len(st.session_state.doc_names)
                        ]
                        notice = "Ø³Ø£Ø±Ø§Ø¬ÙØ¹ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„ØªØ§Ù„ÙŠØ©:\n\n" + "\n".join(
                            f"- `{n}`" for n in selected_names
                        )
                        st.info(notice)
                        st.session_state.messages.append(
                            {
                                "role": "assistant",
                                "content": notice,
                                "is_review_notice": True,
                            }
                        )
                        with st.spinner("ØªØ­Ù…ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©â€¦"):
                            for n in selected_names:
                                _, txt = read_file_content(os.path.join(FOLDER_PATH, n))
                                if txt:
                                    context_docs.append(
                                        Document(page_content=txt, metadata={"source": n})
                                    )
                        final_context = "\n\n---\n\n".join(
                            f"Ø§Ù„Ù…ØµØ¯Ø±: {doc.metadata['source']}\n\nØ§Ù„Ù…Ø­ØªÙˆÙ‰: {doc.page_content}"
                            for doc in context_docs
                        )
                else:
                    st.info("âš™ï¸ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ù…Ø¹Ø·Ù„ â€“ Ø³ÙŠØªÙ… Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙÙ‚Ø·.")
                    final_context = ""

                # ---- Generate the answer ----
                with st.spinner("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯â€¦"):
                    task = "Ø£Ø¬Ø¨ Ø¹Ù† Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ ÙÙ‚Ø·."
                    full_prompt = build_prompt(
                        task, st.session_state.rules_content, final_context, prompt
                    )
                    placeholder = st.empty()
                    answer = ""
                    history_for_api = [
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages[:-1]
                        if not m.get("is_review_notice")
                    ]
                    for chunk in get_deepseek_response_stream(
                        full_prompt, API_KEY, history_for_api, len(context_docs)
                    ):
                        answer += chunk
                        placeholder.markdown(answer + "â–Œ")
                    placeholder.markdown(answer)

                if answer:
                    st.session_state.messages.append(
                        {"role": "assistant", "content": answer}
                    )
                time.sleep(0.1)
                st.rerun()

    # --------------------------------------------------------------------- #
    # Footer â€“ quick actions
    # ---------------------------------------------------------------------- #
    with st.container():
        st.markdown('<div class="footer-actions">', unsafe_allow_html=True)
        st.markdown(
            '<div class="actions-header">Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹Ø©</div>',
            unsafe_allow_html=True,
        )
        col1, col2, col3 = st.columns(3)

        if col1.button("ğŸ“‚ Ø±ÙØ¹", use_container_width=True):
            st.session_state.action = "upload_doc"
            st.rerun()

        if col2.button("ğŸ“„ ØªÙ„Ø®ÙŠØµ", use_container_width=True):
            st.session_state.action = "summarize_doc"
            st.rerun()

        if col3.button("ğŸ§¹ Ù…Ø³Ø­", use_container_width=True):
            st.session_state.messages = []
            st.session_state.action = None
            st.toast("âœ… ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", icon="ğŸ—‘ï¸")
            st.rerun()

        st.markdown("</div>", unsafe_allow_html=True)


if __name__ == "__main__":
    main()